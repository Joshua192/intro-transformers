{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "309e1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import timeit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bbb1fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 512\n",
    "# EPOCHS = 50 # changed to 15 down by the actual training function\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_CLASSES = 10\n",
    "PATCH_SIZE = 4\n",
    "IMG_SIZE = 28\n",
    "IN_CHANNELS = 1\n",
    "NUM_HEADS = 8\n",
    "DROPOUT = 0.001\n",
    "HIDDEN_DIM = 768\n",
    "ADAM_WEIGHT_DECAY = 0\n",
    "# ADAM_BETAS = (0.9, 0.999)\n",
    "ACTIVATION=\"gelu\"\n",
    "NUM_ENCODERS = 4 #encoders in rel life are stacked multiple times\n",
    "EMBED_DIM = (PATCH_SIZE * PATCH_SIZE) * IN_CHANNELS # 16 = H*W * Channels\n",
    "NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2 # 49 = (HWC//Size)^2\n",
    "\n",
    "#stuff I don't yet understand\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d640f2c8",
   "metadata": {},
   "source": [
    "## Create Image Patches, Convert to Embeddings, CLS Token Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c80d4d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 50, 16])\n"
     ]
    }
   ],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, patch_size, num_patches, dropout, in_channels):\n",
    "        super().__init__()\n",
    "        self.patcher = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=embed_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "            ),                  \n",
    "            nn.Flatten(2))\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(size=(1, in_channels, embed_dim)), requires_grad=True)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(size=(1, num_patches+1, embed_dim)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1) # -1, -1 do not modify dim\n",
    "\n",
    "        x = self.patcher(x).permute(0, 2, 1)# image reshape \n",
    "        x = torch.cat([cls_token, x], dim=1) #merge cls_tok w/ patches\n",
    "        x = self.position_embeddings + x \n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "model = PatchEmbedding(EMBED_DIM, PATCH_SIZE, NUM_PATCHES, DROPOUT, IN_CHANNELS).to(device)\n",
    "x = torch.randn(512, 1, 28, 28).to(device) #dummy input for checking work. BATCH_SIZE, INPUT_CHANNELS, IMG_HEIGHT, IMG_WIDTH\n",
    "print(model(x).shape) # model weights, layers and  \n",
    "### 512 - BATCH SIZE , 50 tokens => 49 patches as tokens + 1 cls token, 16 - Size of Patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22d340",
   "metadata": {},
   "source": [
    "## Building Vision Transformer Model (on top of Patches Class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e2e2f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_patches, img_size, num_classes, patch_size, embed_dim, num_encoders, num_heads, hidden_dim, dropout, activation, in_channels):\n",
    "        super().__init__()\n",
    "        self.embeddings_block = PatchEmbedding(embed_dim, patch_size, num_patches, dropout, in_channels)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, activation=activation, batch_first=True, norm_first=True)\n",
    "        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n",
    "        \n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=embed_dim),\n",
    "            nn.Linear(in_features=embed_dim, out_features=num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings_block(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x = self.mlp_head(x[: , 0 , :]) #mlp head needs to take token only\n",
    "        # REMEBER THAT THE CLS TOKEN AT POSN 0 IS A LEARNABLE Feature and its value is influenced by every other (token+img) combo in the \"list\".\n",
    "        # one more layer, a softmax output perhaps? GPT/instructor: Activation fn is for inference not for training, we want to preserve raw logits everywhere else. I was assuming inference too early on.\n",
    "        return x\n",
    "\n",
    "model = ViT(NUM_PATCHES, IMG_SIZE, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, HIDDEN_DIM, DROPOUT, ACTIVATION, IN_CHANNELS).to(device)\n",
    "x = torch.randn(512, 1, 28, 28).to(device)\n",
    "print(model(x).shape) # BATCH_SIZE, NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3438fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #pretend the pass is for one single patch, each patch will be fed in one at a time for a given image. \n",
    "        self.Patch_Embedding \n",
    "        self.Linear = nn.Linear(16,16) #flatten input patch = 4*4 image\n",
    "        #attach position encoding(which I think is just 1, 2, 3. . .)\n",
    "        \n",
    "        self.SelfAttention\n",
    "        # self attention = iterate through list of patches to create vector of sim_score btwn patches. \n",
    "        # Input Embedding (e.g. Word Emb) -> Positional Encoding -> Self-Attention Layer -> Output\n",
    "        #  **(** Normalise(Output + Input Embedding) -> FF Layer (2 FC Layers) -> Normalise(Output + Input$_{2}$ ) **) * N**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518dce15",
   "metadata": {},
   "source": [
    "## Vision Transformer Implementation\n",
    "\n",
    "#### Implementing ViT from Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8b4eb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ViT Implementation. Source: [Implementing Vision Transformer (ViT) from Scratch](https://medium.com/data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0)\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class NewGELUActivation(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT). Also see\n",
    "    the Gaussian Error Linear Units paper: https://arxiv.org/abs/1606.08415\n",
    "\n",
    "    Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/activations.py\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\n",
    "\n",
    "\n",
    "class PatchEmbeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    Convert the image into patches and then project them into a vector space.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.image_size = config[\"image_size\"]\n",
    "        self.patch_size = config[\"patch_size\"]\n",
    "        self.num_channels = config[\"num_channels\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        # Calculate the number of patches from the image size and patch size\n",
    "        self.num_patches = (self.image_size // self.patch_size) ** 2\n",
    "        # Create a projection layer to convert the image into patches\n",
    "        # The layer projects each patch into a vector of size hidden_size\n",
    "        self.projection = nn.Conv2d(self.num_channels, self.hidden_size, kernel_size=self.patch_size, stride=self.patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, num_channels, image_size, image_size) -> (batch_size, num_patches, hidden_size)\n",
    "        x = self.projection(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    Combine the patch embeddings with the class token and position embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.patch_embeddings = PatchEmbeddings(config)\n",
    "        # Create a learnable [CLS] token\n",
    "        # Similar to BERT, the [CLS] token is added to the beginning of the input sequence\n",
    "        # and is used to classify the entire sequence\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, config[\"hidden_size\"]))\n",
    "        # Create position embeddings for the [CLS] token and the patch embeddings\n",
    "        # Add 1 to the sequence length for the [CLS] token\n",
    "        self.position_embeddings = \\\n",
    "            nn.Parameter(torch.randn(1, self.patch_embeddings.num_patches + 1, config[\"hidden_size\"]))\n",
    "        self.dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embeddings(x)\n",
    "        batch_size, _, _ = x.size()\n",
    "        # Expand the [CLS] token to the batch size\n",
    "        # (1, 1, hidden_size) -> (batch_size, 1, hidden_size)\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        # Concatenate the [CLS] token to the beginning of the input sequence\n",
    "        # This results in a sequence length of (num_patches + 1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.position_embeddings\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A single attention head.\n",
    "    This module is used in the MultiHeadAttention module.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, attention_head_size, dropout, bias=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_head_size = attention_head_size\n",
    "        # Create the query, key, and value projection layers\n",
    "        self.query = nn.Linear(hidden_size, attention_head_size, bias=bias)\n",
    "        self.key = nn.Linear(hidden_size, attention_head_size, bias=bias)\n",
    "        self.value = nn.Linear(hidden_size, attention_head_size, bias=bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project the input into query, key, and value\n",
    "        # The same input is used to generate the query, key, and value,\n",
    "        # so it's usually called self-attention.\n",
    "        # (batch_size, sequence_length, hidden_size) -> (batch_size, sequence_length, attention_head_size)\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "        # Calculate the attention scores\n",
    "        # softmax(Q*K.T/sqrt(head_size))*V\n",
    "        attention_scores = torch.matmul(query, key.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "        # Calculate the attention output\n",
    "        attention_output = torch.matmul(attention_probs, value)\n",
    "        return (attention_output, attention_probs)\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head attention module.\n",
    "    This module is used in the TransformerEncoder module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_attention_heads = config[\"num_attention_heads\"]\n",
    "        # The attention head size is the hidden size divided by the number of attention heads\n",
    "        self.attention_head_size = self.hidden_size // self.num_attention_heads\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        # Whether or not to use bias in the query, key, and value projection layers\n",
    "        self.qkv_bias = config[\"qkv_bias\"]\n",
    "        # Create a list of attention heads\n",
    "        self.heads = nn.ModuleList([])\n",
    "        for _ in range(self.num_attention_heads):\n",
    "            head = AttentionHead(\n",
    "                self.hidden_size,\n",
    "                self.attention_head_size,\n",
    "                config[\"attention_probs_dropout_prob\"],\n",
    "                self.qkv_bias\n",
    "            )\n",
    "            self.heads.append(head)\n",
    "        # Create a linear layer to project the attention output back to the hidden size\n",
    "        # In most cases, all_head_size and hidden_size are the same\n",
    "        self.output_projection = nn.Linear(self.all_head_size, self.hidden_size)\n",
    "        self.output_dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        # Calculate the attention output for each attention head\n",
    "        attention_outputs = [head(x) for head in self.heads]\n",
    "        # Concatenate the attention outputs from each attention head\n",
    "        attention_output = torch.cat([attention_output for attention_output, _ in attention_outputs], dim=-1)\n",
    "        # Project the concatenated attention output back to the hidden size\n",
    "        attention_output = self.output_projection(attention_output)\n",
    "        attention_output = self.output_dropout(attention_output)\n",
    "        # Return the attention output and the attention probabilities (optional)\n",
    "        if not output_attentions:\n",
    "            return (attention_output, None)\n",
    "        else:\n",
    "            attention_probs = torch.stack([attention_probs for _, attention_probs in attention_outputs], dim=1)\n",
    "            return (attention_output, attention_probs)\n",
    "\n",
    "\n",
    "class FasterMultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head attention module with some optimizations.\n",
    "    All the heads are processed simultaneously with merged query, key, and value projections.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_attention_heads = config[\"num_attention_heads\"]\n",
    "        # The attention head size is the hidden size divided by the number of attention heads\n",
    "        self.attention_head_size = self.hidden_size // self.num_attention_heads\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        # Whether or not to use bias in the query, key, and value projection layers\n",
    "        self.qkv_bias = config[\"qkv_bias\"]\n",
    "        # Create a linear layer to project the query, key, and value\n",
    "        self.qkv_projection = nn.Linear(self.hidden_size, self.all_head_size * 3, bias=self.qkv_bias)\n",
    "        self.attn_dropout = nn.Dropout(config[\"attention_probs_dropout_prob\"])\n",
    "        # Create a linear layer to project the attention output back to the hidden size\n",
    "        # In most cases, all_head_size and hidden_size are the same\n",
    "        self.output_projection = nn.Linear(self.all_head_size, self.hidden_size)\n",
    "        self.output_dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        # Project the query, key, and value\n",
    "        # (batch_size, sequence_length, hidden_size) -> (batch_size, sequence_length, all_head_size * 3)\n",
    "        qkv = self.qkv_projection(x)\n",
    "        # Split the projected query, key, and value into query, key, and value\n",
    "        # (batch_size, sequence_length, all_head_size * 3) -> (batch_size, sequence_length, all_head_size)\n",
    "        query, key, value = torch.chunk(qkv, 3, dim=-1)\n",
    "        # Resize the query, key, and value to (batch_size, num_attention_heads, sequence_length, attention_head_size)\n",
    "        batch_size, sequence_length, _ = query.size()\n",
    "        query = query.view(batch_size, sequence_length, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
    "        key = key.view(batch_size, sequence_length, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
    "        value = value.view(batch_size, sequence_length, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
    "        # Calculate the attention scores\n",
    "        # softmax(Q*K.T/sqrt(head_size))*V\n",
    "        attention_scores = torch.matmul(query, key.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.attn_dropout(attention_probs)\n",
    "        # Calculate the attention output\n",
    "        attention_output = torch.matmul(attention_probs, value)\n",
    "        # Resize the attention output\n",
    "        # from (batch_size, num_attention_heads, sequence_length, attention_head_size)\n",
    "        # To (batch_size, sequence_length, all_head_size)\n",
    "        attention_output = attention_output.transpose(1, 2) \\\n",
    "                                           .contiguous() \\\n",
    "                                           .view(batch_size, sequence_length, self.all_head_size)\n",
    "        # Project the attention output back to the hidden size\n",
    "        attention_output = self.output_projection(attention_output)\n",
    "        attention_output = self.output_dropout(attention_output)\n",
    "        # Return the attention output and the attention probabilities (optional)\n",
    "        if not output_attentions:\n",
    "            return (attention_output, None)\n",
    "        else:\n",
    "            return (attention_output, attention_probs)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A multi-layer perceptron module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense_1 = nn.Linear(config[\"hidden_size\"], config[\"intermediate_size\"])\n",
    "        self.activation = NewGELUActivation()\n",
    "        self.dense_2 = nn.Linear(config[\"intermediate_size\"], config[\"hidden_size\"])\n",
    "        self.dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    A single transformer block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.use_faster_attention = config.get(\"use_faster_attention\", False)\n",
    "        if self.use_faster_attention:\n",
    "            self.attention = FasterMultiHeadAttention(config)\n",
    "        else:\n",
    "            self.attention = MultiHeadAttention(config)\n",
    "        self.layernorm_1 = nn.LayerNorm(config[\"hidden_size\"])\n",
    "        self.mlp = MLP(config)\n",
    "        self.layernorm_2 = nn.LayerNorm(config[\"hidden_size\"])\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        # Self-attention\n",
    "        attention_output, attention_probs = \\\n",
    "            self.attention(self.layernorm_1(x), output_attentions=output_attentions)\n",
    "        # Skip connection\n",
    "        x = x + attention_output\n",
    "        # Feed-forward network\n",
    "        mlp_output = self.mlp(self.layernorm_2(x))\n",
    "        # Skip connection\n",
    "        x = x + mlp_output\n",
    "        # Return the transformer block's output and the attention probabilities (optional)\n",
    "        if not output_attentions:\n",
    "            return (x, None)\n",
    "        else:\n",
    "            return (x, attention_probs)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The transformer encoder module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # Create a list of transformer blocks\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for _ in range(config[\"num_hidden_layers\"]):\n",
    "            block = Block(config)\n",
    "            self.blocks.append(block)\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        # Calculate the transformer block's output for each block\n",
    "        all_attentions = []\n",
    "        for block in self.blocks:\n",
    "            x, attention_probs = block(x, output_attentions=output_attentions)\n",
    "            if output_attentions:\n",
    "                all_attentions.append(attention_probs)\n",
    "        # Return the encoder's output and the attention probabilities (optional)\n",
    "        if not output_attentions:\n",
    "            return (x, None)\n",
    "        else:\n",
    "            return (x, all_attentions)\n",
    "\n",
    "\n",
    "class ViTForClassfication(nn.Module):\n",
    "    \"\"\"\n",
    "    The ViT model for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.image_size = config[\"image_size\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_classes = config[\"num_classes\"]\n",
    "        # Create the embedding module\n",
    "        self.embedding = Embeddings(config)\n",
    "        # Create the transformer encoder module\n",
    "        self.encoder = Encoder(config)\n",
    "        # Create a linear layer to project the encoder's output to the number of classes\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.num_classes)\n",
    "        # Initialize the weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        # Calculate the embedding output\n",
    "        embedding_output = self.embedding(x)\n",
    "        # Calculate the encoder's output\n",
    "        encoder_output, all_attentions = self.encoder(embedding_output, output_attentions=output_attentions)\n",
    "        # Calculate the logits, take the [CLS] token's output as features for classification\n",
    "        logits = self.classifier(encoder_output[:, 0, :])\n",
    "        # Return the logits and the attention probabilities (optional)\n",
    "        if not output_attentions:\n",
    "            return (logits, None)\n",
    "        else:\n",
    "            return (logits, all_attentions)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=self.config[\"initializer_range\"])\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        elif isinstance(module, Embeddings):\n",
    "            module.position_embeddings.data = nn.init.trunc_normal_(\n",
    "                module.position_embeddings.data.to(torch.float32),\n",
    "                mean=0.0,\n",
    "                std=self.config[\"initializer_range\"],\n",
    "            ).to(module.position_embeddings.dtype)\n",
    "\n",
    "            module.cls_token.data = nn.init.trunc_normal_(\n",
    "                module.cls_token.data.to(torch.float32),\n",
    "                mean=0.0,\n",
    "                std=self.config[\"initializer_range\"],\n",
    "            ).to(module.cls_token.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd44867f",
   "metadata": {},
   "source": [
    "## Training Preparation\n",
    "\n",
    "#### ViT from Scratch Article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "425fd7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5e624a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "# Create data loader for the training dataset\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1426f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Function to visualize images\n",
    "def show_images_with_labels(images, labels):\n",
    "    fig, axes = plt.subplots(len(images)//5, 5, figsize=(10, 2))\n",
    "    for img, label, ax in zip(images, labels, axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Value: {label}')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images from the training data loader\n",
    "data_iter = iter(train_loader)\n",
    "pictures, true_values = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c50c8367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images_with_labels(pictures[10:15], true_values[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "562af511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_patches = 49. 7 rows and 7 columns.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 49 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_image = pictures[0]\n",
    "# split = #picture is a tensor split into 4 patches (get size of one side, split)\n",
    "# print(split_image.shape) #torch.Size([1, 28, 28])\n",
    "print(type(split_image), split_image.shape)\n",
    "\n",
    "# tensor_image = split_image.view(split_image.shape[1], split_image.shape[2], split_image.shape[0])\n",
    "# plt.imshow(split_image.permute(1, 2, 0))# same as shaping with view()\n",
    "# plt.show()\n",
    "# print(\"shaped img: \",type(tensor_image), tensor_image.shape)\n",
    "\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(split_image.squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# def split_into_four(img: Tensor) -> List[Tensor]:\n",
    "#     C, H, W = img.shape\n",
    "\n",
    "#     assert H % 2 == 0 and W % 2 == 0 #\"Height and Width must be even numbers.\"\n",
    "#     top, bottom = torch.split(img, H // 2, dim=1)\n",
    "#     top_left, top_right = torch.split(top, W // 2, dim=2)\n",
    "#     bottom_left, bottom_right = torch.split(bottom, W // 2, dim=2)\n",
    "\n",
    "#     return [top_left, top_right, bottom_left, bottom_right]\n",
    "\n",
    "# split_image = split_into_four(split_image)\n",
    "\n",
    "def patch_generator(img: Tensor, patch_size: int) -> List[Tensor]: \n",
    "    Img_channel, Img_Height, Img_Width = img.shape \n",
    "    \n",
    "    unfold = nn.Unfold(kernel_size=(patch_size,patch_size), stride=(patch_size,patch_size)) #could stride be patch_size*patch_size\n",
    "    patches = unfold(img.unsqueeze(0))\n",
    "    patches = patches.squeeze(0).T #GPT line, not exactly sure the purpose of T?\n",
    "    patches = patches.view(-1, Img_channel, patch_size, patch_size)\n",
    "    return list(patches)\n",
    "\n",
    "patches = patch_generator(split_image, patch_size=4) #PATCH_SIZE not defined yet\n",
    "\n",
    "def show_image(patches, original_img_size, patch_size):  \n",
    "    n_patches = len(patches)\n",
    "    cols = rows = original_img_size // patch_size\n",
    "    print(f\"n_patches = {n_patches}. {rows} rows and {cols} columns.\")\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols, rows))\n",
    "    axes = axes.flatten() #GPT line\n",
    "    for img, ax in zip(patches, axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide any leftover axes\n",
    "    for ax in axes[n_patches:]:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_image(patches, 28, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c22b6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Prepare Data 📊\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "def prepare_data(batch_size=4, num_workers=2):\n",
    "    train_transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        # transforms.Resize((32, 32)),\n",
    "        # transforms.RandomHorizontalFlip(p=0.5),\n",
    "        # transforms.RandomResizedCrop((32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    # trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "    train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=train_transform)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Randomly sample a subset of the training set\n",
    "    indices = torch.randperm(len(train_dataset))[:]\n",
    "    \n",
    "    train_dataset, val_dataset = train_test_split(train_df, test_size=0.1, random_state=RANDOM_SEED, shuffle=True)\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    test_transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        # transforms.Resize((32, 32)),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    # testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "    test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=test_transform) \n",
    "    \n",
    "    \n",
    "    # Randomly sample a subset of the test set\n",
    "    indices = torch.randperm(len(test_dataset))[:]\n",
    "    test_dataset = torch.utils.data.Subset(test_dataset, indices)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    classes = ('0','1','2','3','4','5','6','7','8','9')\n",
    "    return train_loader, val_loader, test_loader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, val_loader, test_loader, classes = prepare_data(batch_size=BATCH_SIZE, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fc8139b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIter = iter(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb15c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: tensor(19854)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4102, in __getitem__\n    indexer = self.columns.get_loc(key)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3809, in get_loc\n    and any(isinstance(x, slice) for x in casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\_tensor.py\", line 1154, in __iter__\n    raise TypeError(\"iteration over a 0-d tensor\")\nTypeError: iteration over a 0-d tensor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pictures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataIter)\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1455\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1505\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1505\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\_utils.py:733\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: tensor(19854)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4102, in __getitem__\n    indexer = self.columns.get_loc(key)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3809, in get_loc\n    and any(isinstance(x, slice) for x in casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Joshua\\anaconda3\\envs\\MLI\\Lib\\site-packages\\torch\\_tensor.py\", line 1154, in __iter__\n    raise TypeError(\"iteration over a 0-d tensor\")\nTypeError: iteration over a 0-d tensor\n"
     ]
    }
   ],
   "source": [
    "# pictures = next(dataIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9705ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_from_dataLoader(images, labels):\n",
    "    fig, axes = plt.subplots(len(images)//5, 5, figsize=(10, 2))\n",
    "    for img, label, ax in zip(images, labels, axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Value: {label}')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "edb99f42",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "show_images_from_dataLoader() missing 1 required positional argument: 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[178], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# show_images_from_dataLoader(pictures[50:55], labels[50:55])\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m show_images_from_dataLoader(pictures[\u001b[38;5;241m50\u001b[39m:\u001b[38;5;241m55\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: show_images_from_dataLoader() missing 1 required positional argument: 'labels'"
     ]
    }
   ],
   "source": [
    "# show_images_from_dataLoader(pictures[50:55], labels[50:55])\n",
    "# show_images_from_dataLoader(pictures[50:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "61b0e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c71073",
   "metadata": {},
   "source": [
    "### Train Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "30d08012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTrain(Dataset):\n",
    "#since this is a pytorch dataset we definitely need init, len, and getitem\n",
    "    def __init__(self, images, labels, indices):\n",
    "        self.images = images # the pixel data (e.g., from your train_df).\n",
    "        self.labels = labels # the ground truth labels (0–9).\n",
    "        self.indices = indices # which rows of the dataframe to use\n",
    "        \n",
    "        \n",
    "        #define the transformations we want to apply to the images\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(), #\tConvert tensor into a PIL Image so we can apply image transformations like rotation.\n",
    "            # transforms.RandomRotation(15), #Randomly rotate the image by up to ±15 degrees \n",
    "            transforms.ToTensor(), # \tConvert back from PIL Image to a PyTorch Tensor\n",
    "            transforms.Normalize([0.5], [0.5]) #Normalize the image to have zero mean and unit variance\n",
    "        ])\n",
    "        #we apply random rotation to make the model more robust to rotation, and normalize the image to have zero mean and unit variance so that model converges faster\n",
    "        # All these transformations are automatically applied every time you load a sample from the dataset!\n",
    "        \n",
    "        #IMPORTANT: only apply transforms to the training set, not the validation or test set\n",
    "        \n",
    "    #when we call len it returns the number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    #when we call getitem it returns the sample at index idx\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28,28)).astype(np.uint8) #we reshape the image to 28x28 (MNIST images are 28x28) and convert to uint8 to be able to apply the transformations\n",
    "        label = self.labels[idx]\n",
    "        index = self.indices[idx]\n",
    "        \n",
    "        image = self.transforms(image) #we need to apply the transformations to the image\n",
    "\n",
    "        return {'image': image, 'label': label, 'index': index} #return a dictionary with the image, label, and index -> this is the train dataset object\n",
    "    \n",
    "    \n",
    "#---- VALIDATION DATASET ---- \n",
    "\n",
    "class MNISTVal(Dataset):\n",
    "    def __init__(self, images, labels, indices):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize([0.5], [0.5]) \n",
    "        ])\n",
    "    \n",
    "    #no transformations needed for validation set because we want the pure results of the dataset with augmentation -> however we can apply normalisation because at inference time, applying normalisation is fine. But applying augementation may harm results. \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28,28)).astype(np.uint8)\n",
    "        label = self.labels[idx]\n",
    "        index = self.indices[idx]\n",
    "        image = self.transforms(image) \n",
    "        \n",
    "        return {'image': image, 'label': label, 'index': index}\n",
    "        \n",
    "\n",
    "class MNISTTEst(Dataset):\n",
    "    def __init__(self, images, indices):\n",
    "        self.images = images\n",
    "        self.indices = indices\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize([0.5], [0.5]) \n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28,28)).astype(np.uint8)\n",
    "        index = self.indices[idx]\n",
    "        image = self.transforms(image) \n",
    "        \n",
    "        return {'image': image, 'index': index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0cff96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Pandas dataframe \n",
    "import pandas as pd\n",
    "# # Train\n",
    "# train_images = train_dataset.data.view(-1, 28*28).numpy()  # flatten images\n",
    "# train_labels = train_dataset.targets.numpy()               # labels\n",
    "\n",
    "# train_df = pd.DataFrame(train_images)\n",
    "# train_df['label'] = train_labels  # add labels at the end\n",
    "\n",
    "# # Test\n",
    "# test_images = test_dataset.data.view(-1, 28*28).numpy()\n",
    "# test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "# test_df = pd.DataFrame(test_images)\n",
    "# test_df['label'] = test_labels\n",
    "\n",
    "#Download MNIST dataset \n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "#Convert to Pandas dataframe \n",
    "# Train\n",
    "train_images = train_dataset.data.view(-1, 28*28).numpy()  # flatten images\n",
    "train_labels = train_dataset.targets.numpy()               # labels\n",
    "\n",
    "train_df = pd.DataFrame(train_images)\n",
    "train_df['label'] = train_labels  # add labels at the end\n",
    "\n",
    "# Test\n",
    "test_images = test_dataset.data.view(-1, 28*28).numpy()\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "test_df = pd.DataFrame(test_images)\n",
    "test_df['label'] = test_labels\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=RANDOM_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d1d955be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5922,\n",
      "           0.9608, -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,\n",
      "           0.9922, -0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,\n",
      "           0.9922, -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,\n",
      "           1.0000, -0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0039,\n",
      "           0.9922, -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3961,\n",
      "           0.9922, -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3961,\n",
      "           0.9922,  0.0980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3961,\n",
      "           0.9922,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.1216,\n",
      "           0.9922,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.2157,\n",
      "           0.9922,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,\n",
      "           0.9922,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,\n",
      "           0.9922, -0.0980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7020,\n",
      "           0.9373, -0.2078, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4824,\n",
      "           0.9765,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5373,\n",
      "           0.9686,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           0.7725,  0.5294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           0.1294,  0.9686, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           0.1294,  0.9922, -0.3569, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           0.1294,  0.9922, -0.3569, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.5765,  0.5216, -0.6000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'label': 1, 'index': 50404}\n",
      "------------------------------\n",
      "6000\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.4667,  0.9216,  0.7804,\n",
      "          -0.6706, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.0039,  0.9294,  0.9765,\n",
      "           0.7725,  0.0118, -0.8353, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.0196,  0.9216,\n",
      "           0.9765,  0.9843,  0.5843, -0.4196, -0.8275, -0.8275, -0.9686,\n",
      "          -0.8275, -0.8275, -0.8980, -0.8275, -0.8275, -0.8275, -0.8275,\n",
      "          -0.9451, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5608,\n",
      "           0.3490,  0.9843,  0.9765,  0.9765,  0.9765,  0.9765,  0.4353,\n",
      "           0.9765,  0.9765,  0.7020,  0.9765,  0.9843,  0.9765,  0.9765,\n",
      "           0.2078, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000,  0.2941,  0.9765,  0.9765,  0.9765,  0.9765,  0.9843,\n",
      "           0.9765,  0.9765,  0.9765,  0.9765,  0.9843,  0.9765,  0.9765,\n",
      "           0.1373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.2314, -0.1686, -0.1686,  0.3176,\n",
      "           0.6549,  0.6549,  0.4510, -0.1686,  0.3725,  0.9843,  0.9843,\n",
      "          -0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.0353,  0.9765,  0.5765,\n",
      "          -0.8353, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.9216,  0.9765, -0.0118,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.7882,  0.9843,  0.9765, -0.5608,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.5216,  0.9843,  0.4275, -0.9686,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.4980,  0.9843,  1.0000, -0.1608, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.1216,  0.9765,  0.8745, -0.6706, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.4275,  0.9294,  0.9765, -0.5137, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.0039,  0.9765,  0.5608, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.7176,  0.7490,  0.9765, -0.6706, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           0.4980,  0.9843,  0.4902, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8824,\n",
      "           0.6549,  0.9765,  0.1373, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.2471,\n",
      "           0.9765,  0.9765,  0.4824, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7098,\n",
      "           0.9765,  0.9765,  0.2706, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.2941,\n",
      "           0.9765, -0.1922, -0.8902, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'label': 7, 'index': 12628}\n",
      "------------------------------\n",
      "10000\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3412,\n",
      "           0.4510,  0.2471,  0.1843, -0.5294, -0.7176, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7412,\n",
      "           0.9922,  0.9922,  0.9922,  0.9922,  0.8902,  0.5529,  0.5529,\n",
      "           0.5529,  0.5529,  0.5529,  0.5529,  0.5529,  0.5529,  0.3333,\n",
      "          -0.5922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4745,\n",
      "          -0.1059, -0.4353, -0.1059,  0.2784,  0.7804,  0.9922,  0.7647,\n",
      "           0.9922,  0.9922,  0.9922,  0.9608,  0.7961,  0.9922,  0.9922,\n",
      "           0.0980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.8667, -0.4824, -0.8902,\n",
      "          -0.4745, -0.4745, -0.4745, -0.5373, -0.8353,  0.8510,  0.9922,\n",
      "          -0.1686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,  0.9843,  0.6392,\n",
      "          -0.8588, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.8275,  0.8275,  1.0000, -0.3490,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.0118,  0.9922,  0.8667, -0.6549,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.5373,  0.9529,  0.9922, -0.5137, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.0431,  0.9922,  0.4667, -0.9608, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.9294,  0.6078,  0.9451, -0.5451, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.0118,  0.9922,  0.4275, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.4118,  0.9686,  0.8824, -0.5529, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8510,\n",
      "           0.7333,  0.9922,  0.3020, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765,  0.5922,\n",
      "           0.9922,  0.7176, -0.7255, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7020,  0.9922,\n",
      "           0.9922, -0.3961, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.7569,  0.7569,  0.9922,\n",
      "          -0.0980, -0.9922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0431,  0.9922,  0.9922,\n",
      "          -0.5922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.5216,  0.8980,  0.9922,  0.9922,\n",
      "          -0.5922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.0510,  0.9922,  0.9922,  0.7176,\n",
      "          -0.6863, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.0510,  0.9922,  0.6235, -0.8588,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'index': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test Image')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAADRCAYAAABsINA8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIxlJREFUeJzt3X9UVHX+P/DngDAg4iigDIgiS5a/MhZNOihCliSBJuZW2g81DEu0WDUj2I+AKZgWa66/NhNqN3/tSTRTj0cSREtZgVUkKds1UfyBP0IBUUHk/f3Dr1PjveoMDHd+8Hycc89ZXtw787rDM/bl5X1nVEIIASIiIiKF2Jm7ASIiImpbOHwQERGRojh8EBERkaI4fBAREZGiOHwQERGRojh8EBERkaI4fBAREZGiOHwQERGRojh8EBERkaLa7PChUqkM2vbs2dOi50lJSYFKpTJN0/+fSqXC9OnTTfqYZBuio6Ph7OyMK1eu3HOfl19+GQ4ODjh//rzBj6tSqZCSkmLQfswmGUKp38EAcO3aNaSkpBj8WOXl5VCpVPjoo49a/Nwkr525GzCXAwcO6H39wQcfIC8vD7m5uXr1vn37tuh5pkyZgpEjR7boMYgMFRMTgy1btmDdunWYNm2a5PvV1dXYvHkzoqKi4OnpaYYOiW5T6ncwcHv4SE1NBQCEhYW1+PGo5drs8PHEE0/ofd2lSxfY2dlJ6ne7du0a2rdvb/Dz+Pj4wMfHp1k9EhkrIiIC3t7eyMzMlB0+1q9fj+vXryMmJsYM3RH9prm/g8k2tNk/uxgiLCwM/fv3x969exEcHIz27dvj9ddfBwBs3LgR4eHh8PLygrOzM/r06YOEhATU1dXpPYbcn1169uyJqKgo7Ny5E4GBgXB2dkbv3r2RmZnZrD737NkDlUqFdevW4b333oOXlxc6dOiAUaNG4fz586itrUVsbCw8PDzg4eGByZMn4+rVq3qPsXz5cgwbNgxdu3aFi4sLHn30USxatAg3b97U208IgbS0NPj6+sLJyQmDBg1CTk4OwsLCJP+iqKmpwezZs+Hn5wdHR0d069YN8fHxkteITMfe3h4TJ05EcXExSktLJd/PysqCl5cXIiIicPHiRUybNg19+/ZFhw4d0LVrVwwfPhz79u0zWT/MJrVEQ0MD5s+fj969e0OtVqNLly6YPHkyLl68qLdfbm4uwsLC4O7uDmdnZ/To0QPPP/88rl27hvLycnTp0gUAkJqaqvtzzqRJk4zq5fPPP4dKpUJubi7eeOMNuLu7o2PHjnjttddQV1eHyspKvPDCC+jUqRO8vLwwe/ZsSUZTU1MRFBQENzc3dOzYEYGBgVizZg3u/nzX+vp6zJo1C1qtFu3bt8ewYcNQXFyMnj17SvqurKzE1KlT4ePjA0dHR/j5+SE1NRWNjY1GnZ/S2uyVD0OdO3cOr7zyCubMmYO0tDTY2d2e1/773//i2WefRXx8PFxcXPDTTz/hww8/xMGDByWXDeWUlJRg1qxZSEhIgKenJz777DPExMTgoYcewrBhw5rVa2JiIp588kl8/vnnKC8vx+zZszF+/Hi0a9cOjz32GNavX49Dhw4hMTERrq6uWLp0qe7Y48ePY8KECbpfxiUlJViwYAF++uknvaEoKSkJ6enpiI2NxdixY1FRUYEpU6bg5s2bePjhh3X7Xbt2DaGhoTh9+jQSExMxYMAAHD16FHPnzkVpaSm+/fZbk6+Fodtef/11LFy4EJmZmfjrX/+qq5eVleHgwYNISEiAvb09qqqqAADJycnQarW4evUqNm/ejLCwMOzevdukl6eZTTJWU1MTnnvuOezbtw9z5sxBcHAwTp48ieTkZISFhaGoqAjOzs4oLy9HZGQkQkJCkJmZiU6dOuHMmTPYuXMnGhoa4OXlhZ07d2LkyJGIiYnBlClTAEA3kBhrypQpGDt2LDZs2KDLbGNjI44dO4axY8ciNjYW3377LT788EN4e3tj5syZumPLy8sxdepU9OjRAwBQUFCAGTNm4MyZM5g7d65uv8mTJ2Pjxo2YM2cOhg8fjrKyMkRHR6Ompkavl8rKSgwePBh2dnaYO3cu/P39ceDAAcyfPx/l5eXIyspq1jkqQpAQQoiJEycKFxcXvVpoaKgAIHbv3n3fY5uamsTNmzdFfn6+ACBKSkp030tOThZ3v8y+vr7CyclJnDx5Ule7fv26cHNzE1OnTn1grwBEXFyc7uu8vDwBQIwaNUpvv/j4eAFAvP3223r1MWPGCDc3t3s+/q1bt8TNmzfFP/7xD2Fvby+qqqqEEEJUVVUJtVotXnzxRb39Dxw4IACI0NBQXS09PV3Y2dmJwsJCvX2/+uorAUDs2LHjgedJzRcaGio8PDxEQ0ODrjZr1iwBQPz888+yxzQ2NoqbN2+Kp556SkRHR+t9D4BITk5+4PMym9Rcd/8OXr9+vQAgNm3apLdfYWGhACBWrFghhPjt53b48OF7PvbFixcNzrAQQpw4cUIAEIsXL9bVsrKyBAAxY8YMvX3HjBkjAIiMjAy9ekBAgAgMDLznc9zJ8rx584S7u7toamoSQghx9OhRAUC89957evvfeT0mTpyoq02dOlV06NBB7/9LhBDio48+EgDE0aNHDTpfc+CfXR6gc+fOGD58uKT+yy+/YMKECdBqtbC3t4eDgwNCQ0MBAD/++OMDHzcgIEA3/QKAk5MTHn74YZw8ebLZvUZFRel93adPHwBAZGSkpF5VVaV3efvQoUMYPXo03N3ddefz2muv4datW/j5558B3J7S6+vr8cILL+g93hNPPIGePXvq1bZt24b+/fsjICAAjY2Nuu2ZZ54x2Qp2ureYmBhcunQJW7duBQA0Njbiyy+/REhICHr16qXbb9WqVQgMDISTkxPatWsHBwcH7N6926AMG4PZJGNt27YNnTp1wqhRo/R+TgEBAdBqtbqfU0BAABwdHREbG4svvvgCv/zyS6v2ZUyW7/59npubi6effhoajUaX5blz5+LXX3/FhQsXAAD5+fkAIMnyuHHj0K6d/h8rtm3bhieffBLe3t56r1FERITeY1kiDh8P4OXlJaldvXoVISEh+Pe//4358+djz549KCwsRHZ2NgDg+vXrD3xcd3d3SU2tVht07L24ubnpfe3o6Hjf+o0bNwAAp06dQkhICM6cOYNPPvkE+/btQ2FhIZYvXw7gt/P59ddfAUD2Lom7a+fPn8eRI0fg4OCgt7m6ukIIgUuXLjX7POnBxo0bB41Go7vsumPHDpw/f15voWlGRgbeeustBAUFYdOmTSgoKEBhYSFGjhzZohzKYTbJWOfPn8eVK1fg6Ogo+VlVVlbqfk7+/v749ttv0bVrV8TFxcHf3x/+/v745JNPWqUvY7J8J8cAcPDgQYSHhwMAVq9eje+//x6FhYVISkoC8OAst2vXTvL/G+fPn8c333wjeX369esHABadZa75eAC5v/3m5ubi7Nmz2LNnj+5qB4D7vreCJduyZQvq6uqQnZ0NX19fXf3w4cN6+90Jvtz7Q1RWVur9C9PDwwPOzs73XETr4eHR8sbpnpydnTF+/HisXr0a586dQ2ZmJlxdXfGnP/1Jt8+XX36JsLAwrFy5Uu/Y2tpapdu9J2az7fLw8IC7uzt27twp+31XV1fd/w4JCUFISAhu3bqFoqIi/O1vf0N8fDw8PT3x0ksvKdXyfW3YsAEODg7Ytm0bnJycdPUtW7bo7ff7LHfr1k1Xb2xs1A0md3h4eGDAgAFYsGCB7HN6e3ubqHvT4/DRDHcGErVarVf/+9//bo52WkzufIQQWL16td5+QUFBUKvV2LhxI8aOHaurFxQU4OTJk3q/4KOiopCWlgZ3d3f4+fm17gmQrJiYGKxatQqLFy/Gjh07MGnSJL3bxFUqlSTDR44cwYEDB9C9e3el25XFbLZdUVFR2LBhA27duoWgoCCDjrG3t0dQUBB69+6NtWvX4j//+Q9eeuklXX5MfUXPGCqVCu3atYO9vb2udv36dfzzn//U2+/ODQcbN25EYGCgrv7VV19J7mCJiorCjh074O/vj86dO7di96bH4aMZgoOD0blzZ7z55ptITk6Gg4MD1q5di5KSEnO31iwjRoyAo6Mjxo8fjzlz5uDGjRtYuXIlLl++rLefm5sbZs6cifT0dHTu3BnR0dE4ffo0UlNT4eXlpbsTCADi4+OxadMmDBs2DH/+858xYMAANDU14dSpU9i1axdmzZpl8C8Uap5BgwZhwIABWLJkCYQQkvf2iIqKwgcffIDk5GSEhobi2LFjmDdvHvz8/CzmNj1ms+166aWXsHbtWjz77LN45513MHjwYDg4OOD06dPIy8vDc889h+joaKxatQq5ubmIjIxEjx49cOPGDd1VraeffhrA7askvr6++Prrr/HUU0/Bzc0NHh4ekvVArSkyMhIZGRmYMGECYmNj8euvv+Kjjz6S/AOgX79+GD9+PD7++GPY29tj+PDhOHr0KD7++GNoNBq9LM+bNw85OTkIDg7G22+/jUceeQQ3btxAeXk5duzYgVWrVlns+0xxzUczuLu7Y/v27Wjfvj1eeeUVvP766+jQoQM2btxo7taapXfv3ti0aRMuX76MsWPHYsaMGQgICNC73fGOBQsWYP78+di+fTtGjx6NpUuXYuXKlejatSs6deqk28/FxQX79u3DpEmT8OmnnyIyMhIvvPACli5dCh8fH0X/o2/LYmJiIIRA3759Jf+HmpSUhFmzZmHNmjWIjIzEZ599hlWrVmHo0KFm6laK2Wy77O3tsXXrViQmJiI7OxvR0dEYM2YMFi5cCCcnJzz66KMAoFs4nJycjIiICLz66qu4ePEitm7dqltjAQBr1qxB+/btMXr0aDz++OMGfVyAKQ0fPhyZmZkoLS3FqFGjkJSUhHHjxiEhIUGyb1ZWFt555x2sWbMGo0aNwoYNG/Cvf/0LAPSy7OXlhaKiIoSHh2Px4sUYOXIkXn31VWRmZiIgIMCir4aohLjr3U2IjHTixAn07t0bycnJSExMNHc7RDrMJtmK/fv3Y8iQIVi7di0mTJhg7nZajMMHGaWkpATr169HcHAwOnbsiGPHjmHRokWoqanBDz/8wM8LIbNhNslW5OTk4MCBAxg4cCCcnZ1RUlKChQsXQqPR4MiRI3oLVq0V13yQUVxcXFBUVIQ1a9bgypUr0Gg0CAsLw4IFC/jLncyK2SRb0bFjR+zatQtLlixBbW0tPDw8EBERgfT0dJsYPABe+SAiIiKFccEpERERKYrDBxERESmq1dZ8rFixAosXL8a5c+fQr18/LFmyBCEhIQ88rqmpCWfPnoWrqys/WZKaTQiB2tpaeHt7690Xb4jmZhdgfqnlmF2yVkZltzU+rW7Dhg3CwcFBrF69WpSVlYl33nlHuLi4SD55T05FRYUAwI2bSbaKigrFssv8cjPlxuxys9bNkOy2yvAxePBg8eabb+rVevfuLRISEh547JUrV8z+wnGzne3KlSuKZZf55WbKjdnlZq2bIdk1+ZqPhoYGFBcX672zHACEh4dj//79kv3r6+tRU1Oj2yzpQ63I+hlz+djY7ALML7UeZpeslSHZNfnwcenSJdy6dUtyX72npycqKysl+6enp0Oj0eg2S/lAK2p7jM0uwPySZWB2ydq02t0ud08+QgjZaej9999HdXW1bquoqGitlogMYmh2AeaXLAuzS9bC5He7eHh4wN7eXjJtX7hwQfZdBtVqteRT/YjMwdjsAswvWQZml6yNya98ODo6YuDAgcjJydGr3/nYXyJLxeyStWJ2yeoYtZzaQHdu+VqzZo0oKysT8fHxwsXFRZSXlz/w2OrqarOv1OVmO1t1dbVi2WV+uZlyY3a5WetmSHZbZfgQQojly5cLX19f4ejoKAIDA0V+fr5Bx/E/AG6m3Iz9Bd6S7DK/3Ey5MbvcrHUzJLsW98FyNTU10Gg05m6DbER1dTU6duyo2PMxv2QqzC5ZK0Oyy892ISIiIkVx+CAiIiJFcfggIiIiRXH4ICIiIkVx+CAiIiJFcfggIiIiRXH4ICIiIkVx+CAiIiJFcfggIiIiRXH4ICIiIkVx+CAiIiJFcfggIiIiRXH4ICIiIkVx+CAiIiJFcfggIiIiRXH4ICIiIkW1M3cD9GCDBg2S1Pbv3y+pDR48WFI7fPhwa7RERETUbLzyQURERIri8EFERESK4vBBREREiuLwQURERIriglMr4OvrK6m1ayf90T300EOSGhecEhGRpeGVDyIiIlIUhw8iIiJSFIcPIiIiUhSHDyIiIlIUF5zakP/973/mboFaydNPPy2pff3115JaVVWVpPbMM8/IPmZZWVnLGyMykXHjxklqb7zxhuy+Z8+eldRu3Lghqa1du1ZSq6yslH1M/v5UFq98EBERkaI4fBAREZGiOHwQERGRojh8EBERkaI4fBAREZGieLeLlVKpVJIa317ddg0ZMkRSk8uAl5eXpLZz507Zx8zKypLUli1bJqldvHjRkBaJWmTRokWSWs+ePVv0mFOnTpXUamtrZfc9evRoi55LCadPn5bU5F43ACgqKmrtdlqEVz6IiIhIURw+iIiISFEcPoiIiEhRHD6IiIhIUVxwagUeffRRSU0IIanx7YFtV2pqqqTW1NQkqSUkJEhq3t7eso/5l7/8RVKLiIiQ1JKTkyW14uJi2ceUI/eW725ubgYde/36ddm6s7Ozwc9viOrqatl6fX29SZ+H7k3urdQHDBggu++PP/4oqfXp00dSCwwMlNTCwsJkH/OJJ56Q1CoqKiS17t27yx5vqMbGRklNblG33OJxOadOnZKtc8EpERER0e9w+CAiIiJFcfggIiIiRXH4ICIiIkUZveB07969WLx4MYqLi3Hu3Dls3rwZY8aM0X1fCIHU1FR8+umnuHz5MoKCgrB8+XL069fPlH23KXKLpsh4tpbdDz74QFLLycmR1GbPni17fHR0tKQml7VvvvmmGd3dv6cRI0YYdOzx48dl6/7+/pKa3Du+yi3MlpOZmSlbj42NNej41mZr2ZWze/dug2r3cq938r1b586dZesBAQGSmtzC6scff9zgnuTcuHFDUvv5558lNblFtXILte/134ilM/rKR11dHR577DHZt2EGbr/Va0ZGBpYtW4bCwkJotVqMGDHinm9pS6QUZpesFbNLtsboKx8RERGyt+MBt6fvJUuWICkpCWPHjgUAfPHFF/D09MS6detk32e/vr5e73a2mpoaY1siMoipswswv6QMZpdsjUnXfJw4cQKVlZUIDw/X1dRqNUJDQ7F//37ZY9LT06HRaHRbS++hJmqO5mQXYH7J/JhdskYmHT4qKysBAJ6ennp1T09P3ffu9v7776O6ulq3yb2pC1Fra052AeaXzI/ZJWvUKu9wevfCLyGE7GIw4PaErlarW6ONNueVV16R1A4fPqx8I1bMmOwClpffgoICSW3cuHGy+65du1ZSe/HFF03e0+//RX6HoQtB5RaWtoZ7vZOqNbH27Crl8uXLsvW8vDyDjjdmEayhnn/+eUlNbmFsaWmppLZx40aT96MEk1750Gq1ACCZti9cuCCZyoksCbNL1orZJWtk0uHDz88PWq1W79a6hoYG5OfnIzg42JRPRWRSzC5ZK2aXrJHRf3a5evWq3geYnThxAocPH4abmxt69OiB+Ph4pKWloVevXujVqxfS0tLQvn17TJgwwaSNExmL2SVrxeySrTF6+CgqKsKTTz6p+3rmzJkAgIkTJ+Lzzz/HnDlzcP36dUybNk33Zje7du2Cq6ur6bomagZml6wVs0u2xujhIyws7L6LxVQqFVJSUpCSktKSvohMjtkla8Xskq1plbtdyDzs7e3N3QJZkZdfftmg2uTJkyU1Jycng58nNDRUUjP0bb/Pnj0rW9+yZYukJndXzejRow16nn379hm0H1FLde3aVVJbsWKFpGZnJ12SOW/ePEmtqqrKNI0pjB8sR0RERIri8EFERESK4vBBREREiuLwQURERIriglMrkJubK6lFRUWZoRNqi7Kyslp0/MqVK03Uyf25ublJaqNGjZLUiouLJbX8/PxW6YnobnFxcZJaly5dJDW5t4E/duxYq/RkDrzyQURERIri8EFERESK4vBBREREiuLwQURERIriglMrYOi7QRK1ZYmJiQbtt337dknt4sWLpm6H2rghQ4bI1hMSEgw6fsyYMZLaDz/80JKWLAqvfBAREZGiOHwQERGRojh8EBERkaI4fBAREZGiuODUCuzcuVNSi4mJMUMnRJahW7dukpqTk5OkJoSQ1Hbt2tUqPRH93rPPPitbd3BwkNR2794tqR04cMDkPVkSXvkgIiIiRXH4ICIiIkVx+CAiIiJFcfggIiIiRXHBqQ05ffq0uVsgUsT69esN2k9ucWlRUZGp26E2ztnZWVIbOXKk7L4NDQ2SWnJysqR28+bNljdmwXjlg4iIiBTF4YOIiIgUxeGDiIiIFMXhg4iIiBTF4YOIiIgUxbtdrEBpaamkVl9fL6nV1NQo0Q6RYsLCwmTrQ4YMkdTs7KT/ltq+fbuk1tjY2OK+iH7v3XffldT++Mc/yu4r93EZ+/fvN3lPlo5XPoiIiEhRHD6IiIhIURw+iIiISFEcPoiIiEhRXHBqBbp16yapOTg4SGp9+/ZVoh0ixTz33HOydSGEpHblyhVJLS8vz9QtURsXGRkpqf3f//2fpHavGwDmzZtn8p6sEa98EBERkaI4fBAREZGiOHwQERGRojh8EBERkaK44NQKNDQ0SGpyC+6IrFlERISkNnXqVIOPl1ucWlZW1qKeqG1zd3eX1JYuXSqp2dvbS2o7duyQfcyCgoKWN2YDeOWDiIiIFMXhg4iIiBTF4YOIiIgUxeGDiIiIFGXUgtP09HRkZ2fjp59+grOzM4KDg/Hhhx/ikUce0e0jhEBqaio+/fRTXL58GUFBQVi+fDn69etn8ubbiu+//15SO3funKQ2aNAgJdqxSsyu5Rs8eLCk5ujoKLtvYWGhpLZ3716T92QJmF1lyC0a3blzp6Tm5+cnqR0/flxSk3vXU/qNUVc+8vPzERcXh4KCAuTk5KCxsRHh4eGoq6vT7bNo0SJkZGRg2bJlKCwshFarxYgRI1BbW2vy5okMxeyStWJ2yRYZdeXj7ikwKysLXbt2RXFxMYYNGwYhBJYsWYKkpCSMHTsWAPDFF1/A09MT69atk71trr6+HvX19bqv7/V++EQt0RrZBZhfan3MLtmiFq35qK6uBgC4ubkBAE6cOIHKykqEh4fr9lGr1QgNDcX+/ftlHyM9PR0ajUa3de/evSUtERnEFNkFmF9SHrNLtqDZw4cQAjNnzsTQoUPRv39/AEBlZSUAwNPTU29fT09P3ffu9v7776O6ulq3VVRUNLclIoOYKrsA80vKYnbJVjT7HU6nT5+OI0eO4LvvvpN8T6VS6X0thJDU7lCr1VCr1c1to83Kzs6W1OLi4iS1sLAw2eP37Nlj4o6sh6myCzC/zfXQQw9JapMmTTL4+JiYGBN2Yz2Y3dbj7+8vqQ0cONCgY2fOnCmpyS1Cpd8068rHjBkzsHXrVuTl5cHHx0dX12q1ACCZti9cuCCZyonMgdkla8Xski0xavgQQmD69OnIzs5Gbm6u5JYjPz8/aLVa5OTk6GoNDQ3Iz89HcHCwaTomagZml6wVs0u2yKg/u8TFxWHdunX4+uuv4erqqpu0NRoNnJ2doVKpEB8fj7S0NPTq1Qu9evVCWloa2rdvjwkTJrTKCRAZgtkla8Xski0yavhYuXIlAOk6gqysLN3fa+fMmYPr169j2rRpuje72bVrF1xdXU3SMFFzMLtkrZhdskVGDR+GfIy7SqVCSkoKUlJSmtsTkckxu2StmF2yRc2+24Usj9zbA3fu3NkMnRDd3+rVqyW1Hj16SGr5+fmyx5eVlZm8J2obfH19Zeu7du0y6Ph3331XUtu2bVuLemqL+MFyREREpCgOH0RERKQoDh9ERESkKA4fREREpCguOCWiVqXRaCQ1Dw8PSU3uro7S0tJW6YnartjYWNm63IJnOXKLoA25I4n08coHERERKYrDBxERESmKwwcREREpisMHERERKYoLTq3UunXrJLXAwEBJ7dSpU0q0Q3RP0dHRklqfPn0MOrZ///6mbofakKFDh0pqM2bMMEMndDde+SAiIiJFcfggIiIiRXH4ICIiIkVx+CAiIiJFccGplTp48KCkNmzYMDN0QnR/iYmJzT72zJkzJuyE2pqQkBBJrUOHDgYff/z4cUnt6tWrLeqJbuOVDyIiIlIUhw8iIiJSFIcPIiIiUhSHDyIiIlIUhw8iIiJSFO92IaJWVVhYKKn94Q9/kNTi4uIktfXr17dKT0R3KykpkdSeeuopSa2qqkqJdmwer3wQERGRojh8EBERkaI4fBAREZGiOHwQERGRolRCCGHuJn6vpqYGGo3G3G2QjaiurkbHjh0Vez7ml0yF2SVrZUh2eeWDiIiIFMXhg4iIiBTF4YOIiIgUZXHDh4UtQSErp3SemF8yFWaXrJUhWbK44aO2ttbcLZANUTpPzC+ZCrNL1sqQLFnc3S5NTU04e/YsXF1dUVtbi+7du6OiokLRVd+tpaamhuejECEEamtr4e3tDTs75WbsO/kVQqBHjx4W+do0hyX/rJvDks+H2TUtS/5ZN4cln48x2bW4z3axs7ODj48PAEClUgEAOnbsaHEvckvwfJRhjtsG7+S3pqYGgOW+Ns3F81EGs2t6PB9lGJpdi/uzCxEREdk2Dh9ERESkKIsePtRqNZKTk6FWq83diknwfNoOW3tteD5th629Njwfy2RxC06JiIjItln0lQ8iIiKyPRw+iIiISFEcPoiIiEhRHD6IiIhIURw+iIiISFEWPXysWLECfn5+cHJywsCBA7Fv3z5zt2SQvXv3YtSoUfD29oZKpcKWLVv0vi+EQEpKCry9veHs7IywsDAcPXrUPM0+QHp6Oh5//HG4urqia9euGDNmDI4dO6a3jzWdj1KYXfNjdpuH2bUMtp5fix0+Nm7ciPj4eCQlJeHQoUMICQlBREQETp06Ze7WHqiurg6PPfYYli1bJvv9RYsWISMjA8uWLUNhYSG0Wi1GjBhhkR/slJ+fj7i4OBQUFCAnJweNjY0IDw9HXV2dbh9rOh8lMLuWgdk1HrNrOWw+v8JCDR48WLz55pt6td69e4uEhAQzddQ8AMTmzZt1Xzc1NQmtVisWLlyoq924cUNoNBqxatUqM3RonAsXLggAIj8/Xwhh/efTGphdy8TsPhiza7lsLb8WeeWjoaEBxcXFCA8P16uHh4dj//79ZurKNE6cOIHKykq9c1Or1QgNDbWKc6uurgYAuLm5AbD+8zE1ZtdyMbv3x+xaNlvLr0UOH5cuXcKtW7fg6empV/f09ERlZaWZujKNO/1b47kJITBz5kwMHToU/fv3B2Dd59MamF3LxOw+GLNruWwxv+3M3cD9qFQqva+FEJKatbLGc5s+fTqOHDmC7777TvI9azyf1mTLr4c1nhuzazhbfj2s9dxsMb8WeeXDw8MD9vb2kuntwoULkinP2mi1WgCwunObMWMGtm7diry8PPj4+Ojq1no+rYXZtTzMrmGYXctkq/m1yOHD0dERAwcORE5Ojl49JycHwcHBZurKNPz8/KDVavXOraGhAfn5+RZ5bkIITJ8+HdnZ2cjNzYWfn5/e963tfFobs2s5mF3jMLuWxebza4ZFrgbZsGGDcHBwEGvWrBFlZWUiPj5euLi4iPLycnO39kC1tbXi0KFD4tChQwKAyMjIEIcOHRInT54UQgixcOFCodFoRHZ2tigtLRXjx48XXl5eoqamxsydS7311ltCo9GIPXv2iHPnzum2a9eu6faxpvNRArNrGZhd4zG7lsPW82uxw4cQQixfvlz4+voKR0dHERgYqLvFyNLl5eUJAJJt4sSJQojbt0glJycLrVYr1Gq1GDZsmCgtLTVv0/cgdx4ARFZWlm4fazofpTC75sfsNg+zaxlsPb8qIYRo3WsrRERERL+xyDUfREREZLs4fBAREZGiOHwQERGRojh8EBERkaI4fBAREZGiOHwQERGRojh8EBERkaI4fBAREZGiOHwQERGRojh8EBERkaI4fBAREZGi/h/F3dHEAKvePQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets test our datasets (just like we tested our models)\n",
    "\n",
    "#plot samples from dataset\n",
    "plt.figure() #creates new empty figure for our plots \n",
    "f, axarr = plt.subplots(1, 3) #creates a 1x3 grid of subplots, f is the figure and axarr is an array of axes (subplots) -> one subplot for each train, test, val set. \n",
    "\n",
    "train_dataset = MNISTTrain(\n",
    "    images=train_df.iloc[:, :-1].values.astype(np.uint8), #we drop the last column (labels) and convert to uint8\n",
    "    labels=train_df['label'].values,\n",
    "    indices=train_df.index.values\n",
    ")\n",
    "\n",
    "#check if len works \n",
    "print(len(train_dataset))\n",
    "\n",
    "#check if getitem works \n",
    "print(train_dataset[0])\n",
    "\n",
    "#show image of data-set \n",
    "axarr[0].imshow(train_dataset[0]['image'].squeeze(), cmap='gray')\n",
    "#note, we know we can access via ['image'] cos we defined it in the dataset class above here: return {'image': image, 'label': label, 'index': index}\n",
    "\n",
    "axarr[0].set_title(f\"Train Image\")\n",
    "\n",
    "print(\"-\"*30)\n",
    "\n",
    "\n",
    "val_dataset = MNISTVal(\n",
    "    images=val_df.iloc[:, :-1].values.astype(np.uint8), \n",
    "    labels=val_df['label'].values,\n",
    "    indices=val_df.index.values\n",
    ")\n",
    "\n",
    "print(len(val_dataset))\n",
    "print(val_dataset[0])\n",
    "axarr[1].imshow(val_dataset[0]['image'].squeeze(), cmap='gray')\n",
    "axarr[1].set_title(f\"Val Image\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "\n",
    "#removed the labels from the test set\n",
    "test_dataset = MNISTTEst(\n",
    "    images=test_df.iloc[:, :-1].values.astype(np.uint8), \n",
    "    indices=test_df.index.values\n",
    ")\n",
    "\n",
    "\n",
    "print(len(test_dataset))\n",
    "print(test_dataset[0])\n",
    "\n",
    "axarr[2].imshow(test_dataset[0]['image'].squeeze(), cmap='gray')\n",
    "axarr[2].set_title(f\"Test Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ad75a",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ede0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "330e791c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [01:56<00:00,  1.10s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.40it/s]\n",
      "  7%|▋         | 1/15 [02:00<28:04, 120.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 1: 0.1718\n",
      "Val loss EPOCH 1: 0.1647\n",
      "Train acc EPOCH 1: 0.9496\n",
      "Val acc EPOCH 1: 0.9515\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [04:09<00:00,  2.35s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.08it/s]\n",
      " 13%|█▎        | 2/15 [06:14<43:06, 198.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 2: 0.1634\n",
      "Val loss EPOCH 2: 0.1576\n",
      "Train acc EPOCH 2: 0.9516\n",
      "Val acc EPOCH 2: 0.9547\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [02:05<00:00,  1.18s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.59it/s]\n",
      " 20%|██        | 3/15 [08:23<33:26, 167.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 3: 0.1519\n",
      "Val loss EPOCH 3: 0.1553\n",
      "Train acc EPOCH 3: 0.9555\n",
      "Val acc EPOCH 3: 0.9530\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [01:51<00:00,  1.05s/it]\n",
      "100%|██████████| 12/12 [00:01<00:00, 11.12it/s]\n",
      " 27%|██▋       | 4/15 [10:16<26:44, 145.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 4: 0.1485\n",
      "Val loss EPOCH 4: 0.1547\n",
      "Train acc EPOCH 4: 0.9564\n",
      "Val acc EPOCH 4: 0.9532\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:39<00:00,  2.66it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00, 10.43it/s]\n",
      " 33%|███▎      | 5/15 [10:58<18:02, 108.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 5: 0.1456\n",
      "Val loss EPOCH 5: 0.1591\n",
      "Train acc EPOCH 5: 0.9574\n",
      "Val acc EPOCH 5: 0.9532\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:40<00:00,  2.65it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.09it/s]\n",
      " 40%|████      | 6/15 [11:42<12:59, 86.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 6: 0.1457\n",
      "Val loss EPOCH 6: 0.1479\n",
      "Train acc EPOCH 6: 0.9573\n",
      "Val acc EPOCH 6: 0.9563\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:56<00:00,  1.87it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  5.58it/s]\n",
      " 47%|████▋     | 7/15 [12:43<10:23, 77.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 7: 0.1413\n",
      "Val loss EPOCH 7: 0.1394\n",
      "Train acc EPOCH 7: 0.9586\n",
      "Val acc EPOCH 7: 0.9595\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:42<00:00,  2.48it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.29it/s]\n",
      " 53%|█████▎    | 8/15 [13:30<07:57, 68.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 8: 0.1375\n",
      "Val loss EPOCH 8: 0.1347\n",
      "Train acc EPOCH 8: 0.9592\n",
      "Val acc EPOCH 8: 0.9600\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [01:42<00:00,  1.04it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.52it/s]\n",
      " 60%|██████    | 9/15 [15:15<07:57, 79.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 9: 0.1405\n",
      "Val loss EPOCH 9: 0.1478\n",
      "Train acc EPOCH 9: 0.9586\n",
      "Val acc EPOCH 9: 0.9575\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:45<00:00,  2.33it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  6.56it/s]\n",
      " 67%|██████▋   | 10/15 [16:03<05:49, 69.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 10: 0.1331\n",
      "Val loss EPOCH 10: 0.1344\n",
      "Train acc EPOCH 10: 0.9598\n",
      "Val acc EPOCH 10: 0.9585\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [01:59<00:00,  1.12s/it]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.43it/s]\n",
      " 73%|███████▎  | 11/15 [18:09<05:47, 86.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 11: 0.1311\n",
      "Val loss EPOCH 11: 0.1331\n",
      "Train acc EPOCH 11: 0.9608\n",
      "Val acc EPOCH 11: 0.9602\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [01:38<00:00,  1.07it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00, 10.22it/s]\n",
      " 80%|████████  | 12/15 [19:49<04:33, 91.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 12: 0.1296\n",
      "Val loss EPOCH 12: 0.1309\n",
      "Train acc EPOCH 12: 0.9610\n",
      "Val acc EPOCH 12: 0.9613\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:38<00:00,  2.76it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 12.50it/s]\n",
      " 87%|████████▋ | 13/15 [20:29<02:31, 75.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 13: 0.1237\n",
      "Val loss EPOCH 13: 0.1356\n",
      "Train acc EPOCH 13: 0.9631\n",
      "Val acc EPOCH 13: 0.9582\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:32<00:00,  3.22it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  5.19it/s]\n",
      " 93%|█████████▎| 14/15 [21:06<01:03, 63.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 14: 0.1255\n",
      "Val loss EPOCH 14: 0.1340\n",
      "Train acc EPOCH 14: 0.9620\n",
      "Val acc EPOCH 14: 0.9590\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:38<00:00,  2.74it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.99it/s]\n",
      "100%|██████████| 15/15 [21:48<00:00, 87.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 15: 0.1231\n",
      "Val loss EPOCH 15: 0.1305\n",
      "Train acc EPOCH 15: 0.9627\n",
      "Val acc EPOCH 15: 0.9608\n",
      "------------------------------\n",
      "Time taken: 1308.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Now we get into training loop \n",
    "from torch import optim\n",
    "ADAM_BETAS = (0.9, 0.999)\n",
    "EPOCHS = 15\n",
    "#define loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY, betas=ADAM_BETAS)\n",
    "\n",
    "#lets estimate the time it will take to train the model \n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "#we add 2 more parameters to the tqdm function: position and leave. \n",
    "for epoch in tqdm(range(EPOCHS), position =0, leave=True):\n",
    "    model.train() #take the model into train mode \n",
    "    \n",
    "    #we need to store train labels and predictions for a given epoch so we can calculate the loss and accuracy for that epoch so we initialise empty lists \n",
    "    train_labels = [] \n",
    "    train_preds = []\n",
    "    train_running_loss = 0.0 #store runnign losss which will start at 0\n",
    "     \n",
    "    #iterate through data loader \n",
    "    for idx, img_label in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "        #remember we return 'image' from dataset class and its a dataframe which is accessible like a dictionary\n",
    "        img = img_label['image'].float().to(device)\n",
    "        label = img_label['label'].type(torch.uint8).to(device) # remember MNIST labels are always integers between 0–9 (digits) so we store as int\n",
    "        y_pred = model(img)\n",
    "        \n",
    "        #recall the output shape is (batch_size, num_classes) aka ([512, 10]), which is a probability distribution over the 10 classes -> so we need to get the index of the highest probability\n",
    "        \n",
    "        \n",
    "        #to predict the label: \n",
    "        y_pred_label = torch.argmax(y_pred, dim=1) #take the column with the highest probability and select it -> dim 1 instead of 0 because we look across the rows of [512, 10] which is the classes\n",
    "        \n",
    "        #add to train labels. store to cpu when we can to avoid using up GPU memory \n",
    "        train_labels.extend(label.cpu().detach())\n",
    "        train_preds.extend(y_pred_label.cpu().detach())\n",
    "        \n",
    "        #3 lines below ensure that training is happening \n",
    "        \n",
    "        loss = criterion(y_pred, label) #calculate the loss -> returns a scalar tensor\n",
    "        optimizer.zero_grad() #zero the parameter gradients\n",
    "        loss.backward() #backpropagate the loss\n",
    "        optimizer.step() #update the model parameters\n",
    "        \n",
    "        #update the loss \n",
    "        train_running_loss += loss.item() #stores the loss for all batches in the epoch\n",
    "    \n",
    "    #now we update the train loss for the whole epoch     \n",
    "    train_loss = train_running_loss / len(train_dataloader) #stores the loss for 1 epoch -> average the loss over the number of batches in the epoch. so we have average loss per batch for 1 epoch. len(train_dataloader) = number of batches in the epoch\n",
    "    \n",
    "    \n",
    "    #calculate train accuracy (num of correct predictions / total num of predictions)\n",
    "    train_acc = sum(x == y for x, y in zip(train_labels, train_preds)) / len(train_labels)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    #take model into evaluation mode \n",
    "    model.eval()\n",
    "    val_labels = [] #store validation labels for a given epoch \n",
    "    val_preds = [] #store validation predictions for a given epoch \n",
    "    val_running_loss = 0.0 #store running loss for a given epoch \n",
    "    \n",
    "    #no need to track gradients in validation loop aka ensures no learning is happening in validation loop -> since we just want validation score from trained model \n",
    "    with torch.no_grad():\n",
    "        for idx, img_label in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "            img = img_label['image'].float().to(device)\n",
    "            label = img_label['label'].type(torch.uint8).to(device)\n",
    "            y_pred = model(img)\n",
    "            \n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "            \n",
    "            val_labels.extend(label.cpu().detach())\n",
    "            val_preds.extend(y_pred_label.cpu().detach())\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "            val_running_loss += loss.item()\n",
    "    val_loss = val_running_loss / len(val_dataloader)\n",
    "    val_acc = sum(x == y for x, y in zip(val_labels, val_preds)) / len(val_labels)\n",
    "\n",
    "            \n",
    "     #print as train happens \n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train loss EPOCH {epoch+1}: {train_loss:.4f}\")       \n",
    "    print(f\"Val loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
    "    print(f\"Train acc EPOCH {epoch+1}: {train_acc:.4f}\")\n",
    "    print(f\"Val acc EPOCH {epoch+1}: {val_acc:.4f}\")\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "stop = timeit.default_timer() \n",
    "print(f\"Time taken: {stop - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1565fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:save model to file\n",
    "\n",
    "torch.save(model.state_dict(), f\"./models/train_one_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3361fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)\n",
    "test_pictures, test_true_values = next(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fc3aad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infer_transform = transforms.Compose(\n",
    "        [\n",
    "        # transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "def model_infer(image):\n",
    "    image = infer_transform(image).unsqueeze(0).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        out = model(image)\n",
    "        # print(f\"out is ==> {out}\")\n",
    "    out = out.argmax(dim=1).item()\n",
    "    return out\n",
    "\n",
    "for index in range(5):\n",
    "    plt.imshow(test_pictures[index].squeeze(), cmap='gray')\n",
    "    plt.title(f\"Prediction: {model_infer(test_pictures[index])}\")\n",
    "    print(f\"True Value: {test_true_values[index]}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
